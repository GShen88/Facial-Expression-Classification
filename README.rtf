{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf100
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww28300\viewh14940\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs48 \cf0 \
For more information about the data and our objective, please see  https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\
\
Coding part is the three .ipynb file. To view it you need the run the Jupyter Notebook.\
\
DeepCNN.ipynb : preprocess the data, build and train the model. Then save the model.\
\
Face_Cropper.ipynb: Automatically detect and crop the face in a photo and compress it to 48x48 grayscale picture.\
\
Emotion_Predictor.ipynb:  Load the saved model. Can be used to predict any face as long as the input is 48x48 grayscale picture.\
\
\
NOTE:\
\
The data file is 101 megabytes and the saved model file is more than 400 megabytes. They are too large so I didn\'92t put them in this folder.}